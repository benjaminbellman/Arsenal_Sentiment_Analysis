{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e37b30a-50a2-40b7-9dfc-63fb6e63cb04",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Arsenal Social Sentiment Analysis\n",
    "## Forecasting User Sentiment between games. \n",
    "by *Ben N. Bellman* \n",
    "<br> Prepared as Springboard Capstone Project\n",
    "<br> *4/13/2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e8249-7334-489c-ad2d-aa4c7724f2a0",
   "metadata": {},
   "source": [
    "<img src=\"../images/who-s-denilo-SuBb_SiEEM8-unsplash.jpg\" style=\"width:800px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe0c02-5bf2-430d-8202-eaf9420c8260",
   "metadata": {
    "tags": []
   },
   "source": [
    "### WARNING: \n",
    "*Although the usernames have been anonymized as to protect the privacy of the users in this analysis, the tweets are still in raw format and may contain inappropriate / sensitive content. Viewer discretion is advised*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d5a26-cafc-4076-8982-27aa1e18d859",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998a7fa5-ca10-4ac4-991a-a1ca7fbeffb7",
   "metadata": {},
   "source": [
    "## Data Mapping: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2cc49c-e7e0-4ec0-9992-0a2ccb0baf9a",
   "metadata": {},
   "source": [
    "One of the important things to know for the analysis is the schedule of the games.\n",
    "The objective in the social sentiment analysis is to predict whether or not a specific tweet is likely to come  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405da87d-8280-4062-b2b2-0c8c98f7eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We start by importing the packages we will use.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scattertext\n",
    "import spacy\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import abline_plot \n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb \n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import mean_squared_error as mse, r2_score, mean_absolute_error as mae, f1_score, fbeta_score \n",
    "from sklearn.metrics import plot_confusion_matrix,classification_report, balanced_accuracy_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, log_loss,matthews_corrcoef, ConfusionMatrixDisplay\n",
    "\n",
    "from io import StringIO \n",
    "from IPython.display import Image,HTML \n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf089cf3-d253-4a4c-9f01-3a73535e99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Functions from pandas module.\n",
    "import sys\n",
    "sys.path.insert(1, './../../Analysis_Functions_For_Pandas')\n",
    "from functions import (preview_data,\n",
    "                       get_missing_counts,\n",
    "                       get_value_counts,\n",
    "                       get_unique_column_count,\n",
    "                       get_datetimes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32465f7b-8d4d-4df3-94fb-cac3dcec2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Data\n",
    "df = pd.read_csv('.\\..\\Data\\Finalized_DataFrame_All_Data_2_Anonymized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcc7ea-cc81-42b7-ac45-796333c83f8c",
   "metadata": {},
   "source": [
    "## I. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291349dd-9ec7-4a34-855d-a6ec6032a00e",
   "metadata": {},
   "source": [
    "We use Twitter Scraper to collect the tweets. There will be a total of **370,000** tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f046b5-6fab-44cd-9895-6fd906ab8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Five Rows of Data: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query2</th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TweetLikes</th>\n",
       "      <th>TweetReplies</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>Result</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:47+00:00</td>\n",
       "      <td>Anonymous19203</td>\n",
       "      <td>@JackAFC01 @LUHG450 @1Thegameis Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:41+00:00</td>\n",
       "      <td>Anonymous123302</td>\n",
       "      <td>@arsenal_lady bei ihm werde ich einfach immer schwach</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:39+00:00</td>\n",
       "      <td>Anonymous134105</td>\n",
       "      <td>5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it @Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:37+00:00</td>\n",
       "      <td>Anonymous112922</td>\n",
       "      <td>@Arsenal @HectorBellerin VAMOS @HectorBellerin ! Even if you stay in Spain, you'll always be loved in North London ;-)</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:32+00:00</td>\n",
       "      <td>Anonymous65885</td>\n",
       "      <td>@Cristiano Come to @Arsenal üêê.. so many assists and crosses with no one to finish/ tap in.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Query2                       Date         Username  \\\n",
       "0  Arsenal until:2022-04-24  2022-04-23 23:59:47+00:00  Anonymous19203    \n",
       "1  Arsenal until:2022-04-24  2022-04-23 23:59:41+00:00  Anonymous123302   \n",
       "2  Arsenal until:2022-04-24  2022-04-23 23:59:39+00:00  Anonymous134105   \n",
       "3  Arsenal until:2022-04-24  2022-04-23 23:59:37+00:00  Anonymous112922   \n",
       "4  Arsenal until:2022-04-24  2022-04-23 23:59:32+00:00  Anonymous65885    \n",
       "\n",
       "                                                                                                                                                                                                                                    Tweet  \\\n",
       "0  @JackAFC01 @LUHG450 @1Thegameis Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now   \n",
       "1  @arsenal_lady bei ihm werde ich einfach immer schwach                                                                                                                                                                                    \n",
       "2  5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it @Arsenal                                                                                                              \n",
       "3  @Arsenal @HectorBellerin VAMOS @HectorBellerin ! Even if you stay in Spain, you'll always be loved in North London ;-)                                                                                                                   \n",
       "4  @Cristiano Come to @Arsenal üêê.. so many assists and crosses with no one to finish/ tap in.                                                                                                                                               \n",
       "\n",
       "   TweetLikes  TweetReplies  RetweetCount  Result     Team  \n",
       "0  1           1             0             1       Arsenal  \n",
       "1  1           0             0             1       Arsenal  \n",
       "2  0           0             0             1       Arsenal  \n",
       "3  18          0             0             1       Arsenal  \n",
       "4  0           0             0             1       Arsenal  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape: \n",
      "\n",
      "(370000, 9)\n",
      "\n",
      " Info: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 370000 entries, 0 to 369999\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   Query2        370000 non-null  object\n",
      " 1   Date          370000 non-null  object\n",
      " 2   Username      370000 non-null  object\n",
      " 3   Tweet         370000 non-null  object\n",
      " 4   TweetLikes    370000 non-null  int64 \n",
      " 5   TweetReplies  370000 non-null  int64 \n",
      " 6   RetweetCount  370000 non-null  int64 \n",
      " 7   Result        370000 non-null  int64 \n",
      " 8   Team          370000 non-null  object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 25.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Start by previewing the data:\n",
    "preview_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e8fe9e-c61c-4447-a01a-b610746ceaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Percentages by Column: \n",
      "\n",
      "Query2 -----> 0 -----> 0.0%\n",
      "Date -----> 0 -----> 0.0%\n",
      "Username -----> 0 -----> 0.0%\n",
      "Tweet -----> 0 -----> 0.0%\n",
      "TweetLikes -----> 0 -----> 0.0%\n",
      "TweetReplies -----> 0 -----> 0.0%\n",
      "RetweetCount -----> 0 -----> 0.0%\n",
      "Result -----> 0 -----> 0.0%\n",
      "Team -----> 0 -----> 0.0%\n"
     ]
    }
   ],
   "source": [
    "## Get the missing values\n",
    "get_missing_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9563e8-2f85-416e-9081-3207c15e4e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in each object column: \n",
      "\n",
      "Query2: 370\n",
      "Date: 317152\n",
      "Username: 200163\n",
      "Tweet: 364939\n",
      "Team: 2\n"
     ]
    }
   ],
   "source": [
    "## Get unique values in each column: \n",
    "get_unique_column_count(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f01ea-368c-4520-97a3-c438104aaaed",
   "metadata": {},
   "source": [
    "## II. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21dcf4e1-2b4b-4028-b005-4c0117583371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query2</th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TweetLikes</th>\n",
       "      <th>TweetReplies</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>Result</th>\n",
       "      <th>Team</th>\n",
       "      <th>CleanTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:47+00:00</td>\n",
       "      <td>Anonymous19203</td>\n",
       "      <td>@JackAFC01 @LUHG450 @1Thegameis Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:41+00:00</td>\n",
       "      <td>Anonymous123302</td>\n",
       "      <td>@arsenal_lady bei ihm werde ich einfach immer schwach</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>bei ihm werde ich einfach immer schwach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:39+00:00</td>\n",
       "      <td>Anonymous134105</td>\n",
       "      <td>5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it @Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Query2                       Date         Username  \\\n",
       "0  Arsenal until:2022-04-24  2022-04-23 23:59:47+00:00  Anonymous19203    \n",
       "1  Arsenal until:2022-04-24  2022-04-23 23:59:41+00:00  Anonymous123302   \n",
       "2  Arsenal until:2022-04-24  2022-04-23 23:59:39+00:00  Anonymous134105   \n",
       "\n",
       "                                                                                                                                                                                                                                    Tweet  \\\n",
       "0  @JackAFC01 @LUHG450 @1Thegameis Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now   \n",
       "1  @arsenal_lady bei ihm werde ich einfach immer schwach                                                                                                                                                                                    \n",
       "2  5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it @Arsenal                                                                                                              \n",
       "\n",
       "   TweetLikes  TweetReplies  RetweetCount  Result     Team  \\\n",
       "0  1           1             0             1       Arsenal   \n",
       "1  1           0             0             1       Arsenal   \n",
       "2  0           0             0             1       Arsenal   \n",
       "\n",
       "                                                                                                                                                                                                  CleanTweet  \n",
       "0     Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now  \n",
       "1   bei ihm werde ich einfach immer schwach                                                                                                                                                                   \n",
       "2  5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it                                                                                         "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove Usernames\n",
    "def remove_usernames_links(tweet):\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub('http[^\\s]+','',tweet)\n",
    "    return tweet\n",
    "df['CleanTweet'] = df['Tweet'].apply(remove_usernames_links)\n",
    "## Preview\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc2e6b9-a896-4314-9ea5-476ec1584445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query2</th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TweetLikes</th>\n",
       "      <th>TweetReplies</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>Result</th>\n",
       "      <th>Team</th>\n",
       "      <th>CleanTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:47+00:00</td>\n",
       "      <td>Anonymous19203</td>\n",
       "      <td>@JackAFC01 @LUHG450 @1Thegameis Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Because you re arsenal and you have no self awareness  in our worst season in years and your best season in years and you only   points ahead of us and you think the gap is that big lol  be real now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:41+00:00</td>\n",
       "      <td>Anonymous123302</td>\n",
       "      <td>@arsenal_lady bei ihm werde ich einfach immer schwach</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>bei ihm werde ich einfach immer schwach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal until:2022-04-24</td>\n",
       "      <td>2022-04-23 23:59:39+00:00</td>\n",
       "      <td>Anonymous134105</td>\n",
       "      <td>5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it @Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>games to go    cup finals     games to UCL or UEL  either way I want my European trips back   We can do it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Query2                       Date         Username  \\\n",
       "0  Arsenal until:2022-04-24  2022-04-23 23:59:47+00:00  Anonymous19203    \n",
       "1  Arsenal until:2022-04-24  2022-04-23 23:59:41+00:00  Anonymous123302   \n",
       "2  Arsenal until:2022-04-24  2022-04-23 23:59:39+00:00  Anonymous134105   \n",
       "\n",
       "                                                                                                                                                                                                                                    Tweet  \\\n",
       "0  @JackAFC01 @LUHG450 @1Thegameis Because you're arsenal and you have no self awareness..in our worst season in years and your best season in years and you only 6 points ahead of us and you think the gap is that big lol ü§£be real now   \n",
       "1  @arsenal_lady bei ihm werde ich einfach immer schwach                                                                                                                                                                                    \n",
       "2  5 games to go\\n\\n5 cup finals \\n\\n5 games to UCL or UEL, either way I want my European trips back.\\n\\nWe can do it @Arsenal                                                                                                              \n",
       "\n",
       "   TweetLikes  TweetReplies  RetweetCount  Result     Team  \\\n",
       "0  1           1             0             1       Arsenal   \n",
       "1  1           0             0             1       Arsenal   \n",
       "2  0           0             0             1       Arsenal   \n",
       "\n",
       "                                                                                                                                                                                                  CleanTweet  \n",
       "0     Because you re arsenal and you have no self awareness  in our worst season in years and your best season in years and you only   points ahead of us and you think the gap is that big lol  be real now  \n",
       "1   bei ihm werde ich einfach immer schwach                                                                                                                                                                   \n",
       "2    games to go    cup finals     games to UCL or UEL  either way I want my European trips back   We can do it                                                                                               "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Replace Punctuation\n",
    "df['CleanTweet'] = df['CleanTweet'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be376f43-8192-4269-80a4-6c3e9b2ab2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect all the tweets in our dataframe and store it into a list.\n",
    "tweets = []\n",
    "for i in df['CleanTweet']:\n",
    "    tweets.append(i)\n",
    "\n",
    "## For each tweet, extract each word and put it into all_words. Remove https links and user mentions.\n",
    "all_words = []\n",
    "for tweet in tweets:\n",
    "    for word in tweet.split(' '):\n",
    "        if word.startswith('https://'):\n",
    "            word = \" \"\n",
    "        if word.startswith('@'):\n",
    "            word = \" \"\n",
    "        if word.startswith('Arse') or word.startswith('arse'):   ##Uncomment to remove all Arsenal mentions.\n",
    "            word = \" \"\n",
    "        if word.startswith('Tott') or word.startswith('totten'): ##Uncomment to remove all Tottenham mentions.  \n",
    "            word = \" \"\n",
    "        if len(word) <= 3:\n",
    "            word = \" \" \n",
    "        all_words.append(word)\n",
    "\n",
    "## Get the first one million words and create a wordcloud.  \n",
    "list_of_words = \" \"\n",
    "for i in all_words: \n",
    "    list_of_words += (i+ \" \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab96074-b8e6-4888-b9ca-3b84f799f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def content_text(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() in stopwords]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48324ae1-c9eb-4f2d-8b65-5ad894c0ca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\benja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\benja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7ed63-778f-4c20-b803-c51cddca68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "allWords = nltk.tokenize.word_tokenize(list_of_words)\n",
    "allWordDist = nltk.FreqDist(w.lower() for w in allWords)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "extra = ['.',\",\",\"#\",\",\",\"!\",\"?\",\"√∞√ø\",\":\",\"‚Äù\",\"'s\"]\n",
    "stopwords.extend(extra)\n",
    "allWordExceptStopDist = nltk.FreqDist(w.lower() for w in allWords if w not in stopwords)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64c529-4195-4a36-b549-3455ff21de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "allWordExceptStopDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d0743-334d-45cc-942a-b84c4022242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df.loc[:,\"Result\"] = df.Result.replace(1,'Win').replace(0,'Loss/Tie')\n",
    "def term_freq(df):\n",
    "    corpus = (scattertext.CorpusFromPandas(df,\n",
    "                                           category_col='Result', \n",
    "                                           text_col='CleanTweet',\n",
    "                                           nlp=nlp)\n",
    "              .build()\n",
    "              .remove_terms(nlp.Defaults.stop_words, ignore_absences=True)\n",
    "              # ignore_absences: if the term does not appear, don't raise an error, just move on.\n",
    "              )\n",
    "    \n",
    "    df = corpus.get_term_freq_df()\n",
    "    df['Winning_Score'] = corpus.get_scaled_f_scores('Win')\n",
    "    df['LossTie_Score'] = corpus.get_scaled_f_scores('Loss/Tie')\n",
    "\n",
    "    df['Winning_Score'] = round(df['Winning_Score'], 2)\n",
    "    df['LossTie_Score'] = round(df['LossTie_Score'], 2)\n",
    "    \n",
    "    df_high = df.sort_values(by='High Rating freq', \n",
    "                             ascending = False).reset_index()\n",
    "    df_low = df.sort_values(by='Low Rating freq', \n",
    "                            ascending=False).reset_index()\n",
    "    \n",
    "    return df_high, df_low\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6097349-a988-4a0a-a38c-b797772c0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Simplified DataFrame\n",
    "simp = df[['Username','Result','CleanTweet','Query2','Team']]\n",
    "simp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e735694-6ab8-4202-94d4-6e27192e8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace 1 with Win and 0 with Loss/Tie\n",
    "simp.loc[:,\"Result\"] = simp.Result.replace(1,'Win').replace(0,'Loss/Tie')\n",
    "simp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f856b1e-4b6f-4608-8928-5e15f0f6a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get info \n",
    "n_tweets = len(simp)\n",
    "n_users = simp.Username.unique().size\n",
    "n_games = simp.Query2.unique().size\n",
    "\n",
    "print(\"Number of tweets: {:d}\".format(n_tweets))\n",
    "print(\"Number of users: {:d}\".format(n_users))\n",
    "print(\"Number of games: {:d}\".format(n_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c01bd-1374-4ee6-a9bb-4bac6a79592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We Create X and y\n",
    "def make_xy(simp, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(simp.CleanTweet)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (simp.Result == 'Win').values.astype(np.int)\n",
    "    #print(vectorizer.get_feature_names())\n",
    "    return X, y\n",
    "X, y = make_xy(simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b04a65-ce3f-4c2e-a089-e99b8107c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test-Split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,y)\n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "train_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "print('Multinomial Naive Bayes')\n",
    "print('Accuracy on the test set: {}'.format(test_accuracy))\n",
    "print('Accuracy on the training set: {}'.format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91265b-aa9b-423c-b2ca-6bc077b3ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word, count the number of documents that contains it \n",
    "count = (X>0).sum(axis=0).tolist()[0]\n",
    "count = sorted(count)\n",
    "n = np.unique(count)\n",
    "\n",
    "# Compute the frequency of words that appear in exactly k documents\n",
    "freq, cat = np.histogram(count, bins = len(n))\n",
    "cumfreq = np.cumsum(freq)\n",
    "cumfreq = np.insert(cumfreq,0,0)\n",
    "n = np.insert(n,0,0)\n",
    "\n",
    "plt.plot(n,cumfreq)\n",
    "plt.xlim(-1,100)\n",
    "plt.xlabel('Count of Documents in which a Word Appears')\n",
    "plt.ylabel('Cumulative Frequency of Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec5c77-18b8-4cfa-b47a-564985dc2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(clf, X, y, scorefunc):\n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
    "        clf.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
    "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b726a-8f4c-40ee-9c7e-3d87960862aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    losstie = y == 0\n",
    "    win = ~losstie\n",
    "    return prob[losstie, 0].sum() + prob[win, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea750a-ff97-404b-8534-c1b9ed15800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain, itest = train_test_split(range(simp.shape[0]), train_size=0.7)\n",
    "mask = np.zeros(simp.shape[0], dtype=np.bool)\n",
    "mask[itest] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec633026-b7f0-42f6-ab20-0e6d40f4334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#the grid of parameters to search over\n",
    "alphas = [0.1, 1, 5, 10, 50]\n",
    "min_dfs = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "best_min_df = None\n",
    "maxscore=-np.inf\n",
    "for alpha in alphas: \n",
    "    for min_df in min_dfs:\n",
    "        vectorizer = CountVectorizer(min_df=min_df)       \n",
    "        Xthis, ythis = make_xy(simp, vectorizer)\n",
    "        Xtrainthis = Xthis[mask]\n",
    "        ytrainthis = ythis[mask]\n",
    "        # Cross validate the NB model and compute a log likelihoood score\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        score = cv_score(clf, Xtrainthis, ytrainthis, scorefunc=log_likelihood)\n",
    "        if score > maxscore:\n",
    "            maxscore = score\n",
    "            best_alpha = alpha\n",
    "            best_min_df = min_df\n",
    "    #print(alpha, best_min_df, maxscore)\n",
    "print(\"Best alpha: {}\\nBest min_df: {}\".format(best_alpha, best_min_df))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2732601-7e18-4f78-9988-aff2d1fb5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=100, stop_words='english')\n",
    "X, y = make_xy(simp, vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "clf = MultinomialNB(alpha=0.5).fit(xtrain, ytrain)\n",
    "\n",
    "#your turn. Print the accuracy on the test and training dataset\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bae074-e627-452c-91fb-da7865c7efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=20, stop_words='english')\n",
    "X, y = make_xy(simp, vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "clf = LogisticRegression().fit(xtrain, ytrain)\n",
    "\n",
    "#your turn. Print the accuracy on the test and training dataset\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264a5f7-87d0-45fd-b456-0d7c190419aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=20, stop_words='english')\n",
    "X, y = make_xy(simp, vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "clf = LogisticRegression().fit(xtrain, ytrain)\n",
    "\n",
    "#your turn. Print the accuracy on the test and training dataset\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b12e6-8888-40a3-b173-3de3cb6b824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Default Metrics: \n",
    "print('Default Accuracy is: {}{}'.format((round(len(simp[simp.Result =='Win']) / len(simp)*100,2)),'%'))\n",
    "print('Default F1 Score is: {}{}'.format((round(len(simp[simp.Result =='Win']) / len(simp)*100,2)),'%'))\n",
    "print('Default Recall is: {}{}'.format((round(len(simp[simp.Result =='Win']) / len(simp)*100,2)),'%'))\n",
    "print('Default Precision is: {}{}'.format((round(len(simp[simp.Result =='Win']) / len(simp)*100,2)),'%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18998a6e-5e69-4b96-952c-a2ffc6618ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "plot_confusion_matrix(clf,xtest,ytest,values_format = '.0f')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d2327-205c-472f-a844-f441efe94c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(xtest.shape[1])\n",
    "probs = clf.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "good_words = words[ind[:30]]\n",
    "bad_words = words[ind[-30:]]\n",
    "\n",
    "good_prob = probs[ind[:30]]\n",
    "bad_prob = probs[ind[-30:]]\n",
    "\n",
    "print(\"Good words\\t     P(Good | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Bad words\\t     P(Good | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fe50a-a896-4f36-b0e4-ac488379d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploring all the Words \n",
    "all_bad_words = \" \".join([word for word in bad_words])\n",
    "wordcloud = WordCloud(width =800, height = 500,\n",
    "                      random_state = 42, max_font_size=100).generate(all_bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31bb90-6d7b-4db1-94ec-4b19566f5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating visualizawtion  for most found words \n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud, interpolation ='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig('.\\..\\images\\All_Tweets_Negative_Words.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b098a1-a5e7-4791-b3da-df4c505a5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploring all the Words \n",
    "all_good_words = \" \".join([word for word in good_words])\n",
    "wordcloud = WordCloud(width =800, height = 500,\n",
    "                      random_state = 42, max_font_size=100).generate(all_good_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993482a1-3803-4865-bd02-b182c49b8c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating visualizawtion  for most found words \n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud, interpolation ='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig('.\\..\\images\\All_Tweets_Positive_Words.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
